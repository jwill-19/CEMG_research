{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3883798c",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f46c39",
   "metadata": {},
   "source": [
    "### Program to conudct 2-sided T tests or KS tests on the data of all intensities within the ___ km buffer from the track files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcceb97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "\n",
    "#track_file1 = \"300km_analysis/IBTrACS.NA.v04r00.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file1 = \"300km_analysis/REF.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file2 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "output_file = \"300km_analysis/kstestcomb_300kmresults_all.txt\"\n",
    "\n",
    "DS1 = xr.open_dataset(track_file1) \n",
    "max_w1 = DS1.vmax_2D.values\n",
    "DS1.close()\n",
    "\n",
    "nstorms1 = np.shape(max_w1)[0]  #get number of storms and times\n",
    "ntimes1 = np.shape(max_w1)[1]\n",
    "\n",
    "n = 0\n",
    "for i in range(nstorms1):       #get number of storms excluding 0 entries\n",
    "    if sum(max_w1[i,:]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        n = n+1\n",
    "\n",
    "new_nstorms1 = n\n",
    "\n",
    "total_list1 = []\n",
    "for i in range(nstorms1):\n",
    "    for j in range(ntimes1):\n",
    "        total_list1.append(max_w1[i,j])\n",
    "\n",
    "total_array1 = np.asarray(total_list1)  #calculate the wind speed for each storm's points in buffer region\n",
    "total_array1 = total_array1[total_array1 > 0] #remove 0 entries\n",
    "#total_array1 = total_array1 * 0.51444444444444    #convert to m/s from knots (if IBTrACS)\n",
    "\n",
    "DS2 = xr.open_dataset(track_file2) \n",
    "max_w2 = DS2.vmax_2D.values\n",
    "DS2.close()\n",
    "\n",
    "nstorms2 = np.shape(max_w2)[0]  #get number of storms and times\n",
    "ntimes2 = np.shape(max_w2)[1]\n",
    "\n",
    "m = 0\n",
    "for i in range(nstorms2):       #get number of storms excluding 0 entries\n",
    "    if sum(max_w2[i,:]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        m = m+1\n",
    "\n",
    "new_nstorms2 = m\n",
    "\n",
    "total_list2 = []\n",
    "for i in range(nstorms2):\n",
    "    for j in range(ntimes2):\n",
    "        total_list2.append(max_w2[i,j])\n",
    "\n",
    "total_array2 = np.asarray(total_list2)  #calculate the wind speed for each storm's points in buffer region\n",
    "total_array2 = total_array2[total_array2 > 0] #remove 0 entries\n",
    "\n",
    "#statistic, pvalue = stats.ttest_ind(total_array1, total_array2, equal_var = False, nan_policy = 'omit')\n",
    "statistic, pvalue = stats.ks_2samp(total_array1, total_array2, alternative='less')\n",
    "\n",
    "with open(output_file, 'a') as file:\n",
    "    file.write(\"2 Sample KS Test on all intensities from the files (alt:'less'): \\n\")\n",
    "    file.write(track_file1 + \": nstorms = \" + str(new_nstorms1) + \"\\n\" )\n",
    "    file.write(track_file2 + \": nstorms = \" + str(new_nstorms2) + \"\\n\")\n",
    "    file.write(\"statistic = \" + str(statistic) + \"\\n\")\n",
    "    file.write(\"p value = \" + str(pvalue) + \"\\n\")\n",
    "    if pvalue < 0.05:\n",
    "        file.write(\"STATISTICALLY SIGNIFICANT DIFFERENCE \\n\")\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926fa2a3",
   "metadata": {},
   "source": [
    "### Program to conudct 2-sided T tests or KS tests on the data of max intensities within the ___ km buffer from the track files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ecc60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "\n",
    "#track_file1 = \"200km_analysis/IBTrACS.NA.v04r00.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file1 = \"300km_analysis/REF.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file2 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "output_file = \"300km_analysis/kstestcomb_300kmresults_max.txt\"\n",
    "\n",
    "DS1 = xr.open_dataset(track_file1) \n",
    "max_w1 = DS1.vmax_2D.values\n",
    "DS1.close()\n",
    "\n",
    "nstorms1 = np.shape(max_w1)[0]  #get number of storms and times\n",
    "ntimes1 = np.shape(max_w1)[1]\n",
    "\n",
    "n = 0\n",
    "for i in range(nstorms1):       #get number of storms excluding 0 entries\n",
    "    if sum(max_w1[i,:]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        n = n+1\n",
    "\n",
    "new_nstorms1 = n\n",
    "\n",
    "max_list1 = []\n",
    "for i in range(nstorms1):\n",
    "    max_int1 = max(max_w1[i,:])\n",
    "    max_list1.append(max_int1)\n",
    "\n",
    "max_array1 = np.asarray(max_list1)          #calculate the max wind speed for each storm's points in buffer region\n",
    "max_array1 = max_array1[max_array1 > 0]     #remove 0 entries\n",
    "#max_array1 = max_array1 * 0.51444444444444  #convert to m/s if file is IBTrACS\n",
    "\n",
    "DS2 = xr.open_dataset(track_file2) \n",
    "max_w2 = DS2.vmax_2D.values\n",
    "DS2.close()\n",
    "\n",
    "nstorms2 = np.shape(max_w2)[0]  #get number of storms and times\n",
    "ntimes2 = np.shape(max_w2)[1]\n",
    "\n",
    "m = 0\n",
    "for i in range(nstorms2):       #get number of storms excluding 0 entries\n",
    "    if sum(max_w2[i,:]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        m = m+1\n",
    "\n",
    "new_nstorms2 = m\n",
    "\n",
    "max_list2 = []\n",
    "for i in range(nstorms2):\n",
    "    max_int2 = max(max_w2[i,:])\n",
    "    max_list2.append(max_int2)\n",
    "\n",
    "max_array2 = np.asarray(max_list2)      #calculate the max wind speed for each storm's points in buffer region\n",
    "max_array2 = max_array2[max_array2 > 0] #remove 0 entries\n",
    "\n",
    "#statistic, pvalue = stats.ttest_ind(max_array1, max_array2, equal_var = False, nan_policy = 'omit')\n",
    "statistic, pvalue = stats.ks_2samp(max_array1, max_array2, alternative='less')\n",
    "\n",
    "with open(output_file, 'a') as file:\n",
    "    file.write(\"2 Sample KS Test on the max intensities from the files (alt='less'): \\n\")\n",
    "    file.write(track_file1 + \": nstorms = \" + str(new_nstorms1) + \"\\n\" )\n",
    "    file.write(track_file2 + \": nstorms = \" + str(new_nstorms2) + \"\\n\")\n",
    "    file.write(\"statistic = \" + str(statistic) + \"\\n\")\n",
    "    file.write(\"p value = \" + str(pvalue) + \"\\n\")\n",
    "    if pvalue < 0.05:\n",
    "        file.write(\"STATISTICALLY SIGNIFICANT DIFFERENCE \\n\")\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf3213",
   "metadata": {},
   "source": [
    "### Program to conudct 2-sided T tests or KS tests on the data of average intensities within the ___ km buffer from the track files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d894ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "\n",
    "#track_file1 = \"200km_analysis/IBTrACS.NA.v04r00.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file1 = \"300km_analysis/REF.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file2 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "output_file = \"300km_analysis/kstestcomb_300kmresults_avg.txt\"\n",
    "\n",
    "DS1 = xr.open_dataset(track_file1) \n",
    "max_w1 = DS1.vmax_2D.values\n",
    "DS1.close()\n",
    "\n",
    "nstorms1 = np.shape(max_w1)[0]  #get number of storms and times\n",
    "ntimes1 = np.shape(max_w1)[1]\n",
    "\n",
    "n = 0\n",
    "for i in range(nstorms1):       #get number of storms excluding 0 entries\n",
    "    if sum(max_w1[i,:]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        n = n+1\n",
    "\n",
    "new_nstorms1 = n\n",
    "\n",
    "avg_list1 = []\n",
    "for i in range(nstorms1):\n",
    "    k = 0\n",
    "    storm1 = max_w1[i,:]\n",
    "    storm1 = storm1[storm1 > 0]\n",
    "    if len(storm1) == 0:\n",
    "        avg_int1 = 0\n",
    "    else:\n",
    "        avg_int1 = statistics.mean(storm1)\n",
    "    avg_list1.append(avg_int1)\n",
    "\n",
    "avg_array1 = np.asarray(avg_list1)         #calculate the avg wind speed for each storm's points in buffer region\n",
    "avg_array1 = avg_array1[avg_array1 > 0]    #remove 0 entries\n",
    "#avg_array1 = avg_array1 * 0.51444444444444 #convert to m/s if file is IBTrACS\n",
    "\n",
    "DS2 = xr.open_dataset(track_file2) \n",
    "max_w2 = DS2.vmax_2D.values\n",
    "DS2.close()\n",
    "\n",
    "nstorms2 = np.shape(max_w2)[0]  #get number of storms and times\n",
    "ntimes2 = np.shape(max_w2)[1]\n",
    "\n",
    "m = 0\n",
    "for i in range(nstorms2):       #get number of storms excluding 0 entries\n",
    "    if sum(max_w2[i,:]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        m = m+1\n",
    "\n",
    "new_nstorms2 = m\n",
    "\n",
    "avg_list2 = []\n",
    "for i in range(nstorms2):\n",
    "    k = 0\n",
    "    storm2 = max_w2[i,:]\n",
    "    storm2 = storm2[storm2 > 0]\n",
    "    if len(storm2) == 0:\n",
    "        avg_int2 = 0\n",
    "    else:\n",
    "        avg_int2 = statistics.mean(storm2)\n",
    "    avg_list2.append(avg_int2)\n",
    "\n",
    "avg_array2 = np.asarray(avg_list2)      #calculate the avg wind speed for each storm's points in buffer region\n",
    "avg_array2 = avg_array2[avg_array2 > 0] #remove 0 entries\n",
    "\n",
    "#statistic, pvalue = stats.ttest_ind(avg_array1, avg_array2, equal_var = False, nan_policy = 'omit')\n",
    "statistic, pvalue = stats.ks_2samp(avg_array1, avg_array2, alternative='less')\n",
    "\n",
    "with open(output_file, 'a') as file:\n",
    "    file.write(\"2 Sample KS Test on the avg intensities from the files (alt='less'): \\n\")\n",
    "    file.write(track_file1 + \": nstorms = \" + str(new_nstorms1) + \"\\n\" )\n",
    "    file.write(track_file2 + \": nstorms = \" + str(new_nstorms2) + \"\\n\")\n",
    "    file.write(\"statistic = \" + str(statistic) + \"\\n\")\n",
    "    file.write(\"p value = \" + str(pvalue) + \"\\n\")\n",
    "    if pvalue < 0.05:\n",
    "        file.write(\"STATISTICALLY SIGNIFICANT DIFFERENCE \\n\")\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33327429",
   "metadata": {},
   "source": [
    "### Program to conduct 2 sample KS tests on the translation speed distributions of two specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c67875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tc_analysis.tc_functions import *\n",
    "\n",
    "#track_file1 = \"200km_analysis/IBTrACS.NA.v04r00.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file1 = \"100km_analysis/REF.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file2 = \"100km_analysis/RCP85.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "output_file = \"100km_analysis/kstest_ts_100kmresults.txt\"\n",
    "\n",
    "alt_hyp = \"less\"\n",
    "\n",
    "file_array = np.array([track_file1, track_file2])   #put files into an array\n",
    "\n",
    "files = np.shape(file_array)[0]              #get number of files\n",
    "\n",
    "ts_list = []\n",
    "len_list = []\n",
    "\n",
    "for j in range(files):                       #iterate through every track file \n",
    "    ts_dist = []                             #initialize ts distribution list\n",
    "        \n",
    "    DS = xr.open_dataset(file_array[j])      #open file and extract arrays\n",
    "    lons = DS.clon.values\n",
    "    lats = DS.clat.values\n",
    "    time = DS.time_str.values\n",
    "    DS.close()\n",
    "        \n",
    "    nstorms = np.shape(lons)[0]              #get number of storms and times\n",
    "    ntimes = np.shape(lons)[1]\n",
    "        \n",
    "    for k in range(nstorms):\n",
    "        lon_array = lons[k,:]                #get lons and lats for each storm\n",
    "        lat_array = lats[k,:]\n",
    "        lon_array = lon_array[lon_array < 0] #only keep legitimate TC track points\n",
    "        lat_array = lat_array[lat_array > 0]\n",
    "    \n",
    "        if len(lon_array) != len(lat_array): #raise error if not all points have both a lon and lat coord\n",
    "            raise ValueError('lat/lon lengths are not equal at storm ' + str(i))\n",
    "    \n",
    "        for m in range(len(lon_array)):\n",
    "                \n",
    "            if m == len(lon_array)-1:        #avoid conflicts at last point \n",
    "                continue\n",
    "            \n",
    "            if file_array[j].count('IBTrACS') == 1:\n",
    "                time1 = np.datetime64(time[k,m].decode('UTF-8'))       \n",
    "                time2 = np.datetime64(time[k,m+1].decode('UTF-8'))\n",
    "                    \n",
    "            if file_array[j].count('IBTrACS') == 0:\n",
    "                time1_str = str(time[k,m])                #get initial strings in integer format\n",
    "                time2_str = str(time[k,m+1])              #convert to np.datetime64 format\n",
    "                time1_dt = time1_str[0:4] + '-' + time1_str[4:6] + '-' + time1_str[6:8] + ' ' + time1_str[8:10] + ':00:00'\n",
    "                time2_dt = time2_str[0:4] + '-' + time2_str[4:6] + '-' + time2_str[6:8] + ' ' + time2_str[8:10] + ':00:00'\n",
    "                time1 = np.datetime64(time1_dt)\n",
    "                time2 = np.datetime64(time2_dt)\n",
    "                    \n",
    "            time_diff = np.timedelta64(time2-time1, 'h')  #get difference in times\n",
    "            expected_diff = np.timedelta64(6, 'h')        #set expected difference to 6 hours\n",
    "            hours = 6.0                                   #numerical value of expected time diff between pts\n",
    "                \n",
    "            if time_diff == expected_diff:                #all time differences should equal expected difference\n",
    "                track_pt1 = (lon_array[m], lat_array[m])  #calculate translation speed in km/h for each point\n",
    "                track_pt2 = (lon_array[m+1], lat_array[m+1])\n",
    "                ts = get_distance(track_pt1, track_pt2) / hours \n",
    "                ts_dist.append(ts)\n",
    "        \n",
    "    ts_list.append(ts_dist)              #append arrays into list\n",
    "    len_list.append(len(ts_dist))        #append length of distribution to lengths list\n",
    "        \n",
    "ts_array = np.asarray(ts_list)           #convert to np.ndarray\n",
    "\n",
    "statistic, pvalue = stats.ks_2samp(ts_array[0], ts_array[1], \n",
    "                                   alternative=alt_hyp)  #conduct 2 sample KS test and output results to text file\n",
    " \n",
    "with open(output_file, 'a') as file:\n",
    "    file.write(\"2 Sample KS test on the ts distributions from the files (alt=\" + alt_hyp + \"): \\n\")\n",
    "    file.write(track_file1 + \": num data points = \" + str(len_list[0]) + \"\\n\" )\n",
    "    file.write(track_file2 + \": num data points = \" + str(len_list[1]) + \"\\n\")\n",
    "    file.write(\"statistic = \" + str(statistic) + \"\\n\")\n",
    "    file.write(\"p value = \" + str(pvalue) + \"\\n\")\n",
    "    if pvalue < 0.05:\n",
    "        file.write(\"STATISTICALLY SIGNIFICANT DIFFERENCE \\n\")\n",
    "    file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
