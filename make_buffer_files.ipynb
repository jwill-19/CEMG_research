{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f24f06",
   "metadata": {},
   "source": [
    "# Program to make files for the NA basin, land, and all buffer regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5801bc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC-Earth3P-HR(19852014)(1):\n",
      "Landfall storms\n",
      "(55, 106)\n",
      "(10, 106)\n",
      "Landfall points\n",
      "(10, 106)\n",
      "(10, 106)\n",
      "100km:\n",
      "Landfall filter 100km\n",
      "(55, 106)\n",
      "(11, 106)\n",
      "Ocean points\n",
      "(11, 106)\n",
      "(11, 106)\n",
      "100km buffer points\n",
      "(11, 106)\n",
      "(11, 106)\n",
      "200km:\n",
      "Landfall filter 200km\n",
      "(55, 106)\n",
      "(11, 106)\n",
      "Ocean points\n",
      "(11, 106)\n",
      "(11, 106)\n",
      "200km buffer points\n",
      "(11, 106)\n",
      "(11, 106)\n",
      "300km:\n",
      "Landfall filter 300km\n",
      "(55, 106)\n",
      "(11, 106)\n",
      "Ocean points\n",
      "(11, 106)\n",
      "(11, 106)\n",
      "300km buffer points\n",
      "(11, 106)\n",
      "(11, 106)\n",
      "EC-Earth3P-HR(19852014)(2):\n",
      "Landfall storms\n",
      "(47, 94)\n",
      "(7, 94)\n",
      "Landfall points\n",
      "(7, 94)\n",
      "(7, 94)\n",
      "100km:\n",
      "Landfall filter 100km\n",
      "(47, 94)\n",
      "(8, 94)\n",
      "Ocean points\n",
      "(8, 94)\n",
      "(8, 94)\n",
      "100km buffer points\n",
      "(8, 94)\n",
      "(8, 94)\n",
      "200km:\n",
      "Landfall filter 200km\n",
      "(47, 94)\n",
      "(12, 94)\n",
      "Ocean points\n",
      "(12, 94)\n",
      "(12, 94)\n",
      "200km buffer points\n",
      "(12, 94)\n",
      "(12, 94)\n",
      "300km:\n",
      "Landfall filter 300km\n",
      "(47, 94)\n",
      "(14, 94)\n",
      "Ocean points\n",
      "(14, 94)\n",
      "(14, 94)\n",
      "300km buffer points\n",
      "(14, 94)\n",
      "(14, 94)\n",
      "EC-Earth3P-HR(20212050)(1):\n",
      "Landfall storms\n",
      "(58, 96)\n",
      "(11, 96)\n",
      "Landfall points\n",
      "(11, 96)\n",
      "(11, 96)\n",
      "100km:\n",
      "Landfall filter 100km\n",
      "(58, 96)\n",
      "(14, 96)\n",
      "Ocean points\n",
      "(14, 96)\n",
      "(14, 96)\n",
      "100km buffer points\n",
      "(14, 96)\n",
      "(14, 96)\n",
      "200km:\n",
      "Landfall filter 200km\n",
      "(58, 96)\n",
      "(15, 96)\n",
      "Ocean points\n",
      "(15, 96)\n",
      "(15, 96)\n",
      "200km buffer points\n",
      "(15, 96)\n",
      "(15, 96)\n",
      "300km:\n",
      "Landfall filter 300km\n",
      "(58, 96)\n",
      "(19, 96)\n",
      "Ocean points\n",
      "(19, 96)\n",
      "(19, 96)\n",
      "300km buffer points\n",
      "(19, 96)\n",
      "(19, 96)\n",
      "EC-Earth3P-HR(20212050)(2):\n",
      "Landfall storms\n",
      "(47, 103)\n",
      "(6, 103)\n",
      "Landfall points\n",
      "(6, 103)\n",
      "(6, 103)\n",
      "100km:\n",
      "Landfall filter 100km\n",
      "(47, 103)\n",
      "(8, 103)\n",
      "Ocean points\n",
      "(8, 103)\n",
      "(8, 103)\n",
      "100km buffer points\n",
      "(8, 103)\n",
      "(8, 103)\n",
      "200km:\n",
      "Landfall filter 200km\n",
      "(47, 103)\n",
      "(9, 103)\n",
      "Ocean points\n",
      "(9, 103)\n",
      "(9, 103)\n",
      "200km buffer points\n",
      "(9, 103)\n",
      "(9, 103)\n",
      "300km:\n",
      "Landfall filter 300km\n",
      "(47, 103)\n",
      "(9, 103)\n",
      "Ocean points\n",
      "(9, 103)\n",
      "(9, 103)\n",
      "300km buffer points\n",
      "(9, 103)\n",
      "(9, 103)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from tc_functions.loc_constraints import landfall_filter, remove_unwanted_points\n",
    "from tc_functions.loc_constraints import get_landfall_points, get_ocean_points\n",
    "from tc_functions.plotting import plot_tc_points\n",
    "\n",
    "distance = ['100km', '200km', '300km']    #list of buffer regions\n",
    "general_model = 'EC-Earth3P-HR'\n",
    "model = ['EC-Earth3P-HR(19852014)(1)', 'EC-Earth3P-HR(19852014)(2)', 'EC-Earth3P-HR(20212050)(1)', \n",
    "         'EC-Earth3P-HR(20212050)(2)']    #list of models\n",
    "todays_date = '2022-01-11'                #YYYY-MM-DD\n",
    "                                          \n",
    "for i in range(len(model)):\n",
    "    \n",
    "    print(f'{model[i]}:')     #open track file and extract values\n",
    "        \n",
    "    track_file = f'HighResMIP/{general_model}/na_basin/{model[i]}.NA.storms.nc'\n",
    "    DS = xr.open_dataset(track_file)\n",
    "    lons = DS.clon.values\n",
    "    lats = DS.clat.values\n",
    "    max_w = DS.vmax_2D.values\n",
    "    try:\n",
    "        time = DS.time_byte.values\n",
    "    except AttributeError:\n",
    "        time = DS.time_str.values\n",
    "    DS.close()\n",
    "    \n",
    "    us_shapefile = 'shapefiles/eastern_us.shp'\n",
    "    \n",
    "    #find all TCs that make landfall with the eastern US coast. Save to NetCDF file\n",
    "    \n",
    "    print('Landfall storms')\n",
    "    print(np.shape(lons))\n",
    "    lons1, lats1, max_w1, time1 = landfall_filter(lons, lats, max_w, time, us_shapefile)  \n",
    "        \n",
    "    new_ds1 = xr.Dataset(\n",
    "        data_vars = dict(\n",
    "        clon = ([\"stormID\", \"time\"], lons1),\n",
    "        clat = ([\"stormID\", \"time\"], lats1),\n",
    "        vmax_2D = ([\"stormID\", \"time\"], max_w1),\n",
    "        time_byte = ([\"stormID\", \"time\"], time1)\n",
    "        ),\n",
    "        attrs = dict(\n",
    "        description = \"Simple NetCDF file with updated longitude, latitude, maximum wind speed, \" \n",
    "                    \"and times for all NA landfalling storms (tropical depressions not included) \" \n",
    "                    f\"from the model {model[i]}.\",\n",
    "        author = \"Justin Willson\",\n",
    "        creation_date = todays_date\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    new_ds1.to_netcdf(f\"HighResMIP/{general_model}/na_basin/{model[i]}.NA.landfalling.storms.nc\")\n",
    "    \n",
    "    #find all points on land. Save to NetCDF file\n",
    "    \n",
    "    print('Landfall points')\n",
    "    print(np.shape(lons1))\n",
    "    lons2, lats2, max_w2, time2 = get_landfall_points(lons1, lats1, max_w1, time1, us_shapefile)  \n",
    "                                          \n",
    "    new_ds2 = xr.Dataset(\n",
    "        data_vars = dict(\n",
    "        clon = ([\"stormID\", \"time\"], lons2),\n",
    "        clat = ([\"stormID\", \"time\"], lats2),\n",
    "        vmax_2D = ([\"stormID\", \"time\"], max_w2),\n",
    "        time_byte = ([\"stormID\", \"time\"], time2)\n",
    "        ),\n",
    "        attrs = dict(\n",
    "        description = \"Simple NetCDF file with updated longitude, latitude, maximum wind speed, \" \n",
    "                    \"and times for all storm (tropical depressions not included) points that are on land \"\n",
    "                    f\"for the model {model[i]}.\",\n",
    "        author = \"Justin Willson\",\n",
    "        creation_date = todays_date\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    new_ds2.to_netcdf(f\"HighResMIP/{general_model}/na_basin/{model[i]}.NA.landfalling.storms.land.pts.nc\")\n",
    "    \n",
    "    \n",
    "    for j in range(len(distance)):\n",
    "        \n",
    "        print(f'{distance[j]}:')\n",
    "        \n",
    "        buffer_shapefile = f'shapefiles/eastern_us_{distance[j]}.shp'\n",
    "        \n",
    "        #find all storms that intersect the specified buffer region. Save to NetCDF file\n",
    "        \n",
    "        print(f'Landfall filter {distance[j]}')\n",
    "        print(np.shape(lons))\n",
    "        lons3, lats3, max_w3, time3 = landfall_filter(lons, lats, max_w, time, buffer_shapefile) \n",
    "        \n",
    "        new_ds3 = xr.Dataset(\n",
    "            data_vars = dict(\n",
    "            clon = ([\"stormID\", \"time\"], lons3),\n",
    "            clat = ([\"stormID\", \"time\"], lats3),\n",
    "            vmax_2D = ([\"stormID\", \"time\"], max_w3),\n",
    "            time_byte = ([\"stormID\", \"time\"], time3)\n",
    "            ),\n",
    "            attrs = dict(\n",
    "            description = \"Simple NetCDF file with updated longitude, latitude, maximum wind speed, \" \n",
    "                          \"and times for all NA storms (tropical depressions not included) that come \" \n",
    "                          f\"within {distance[j]} of the eastern US for the model {model[i]}.\",\n",
    "            author = \"Justin Willson\",\n",
    "            creation_date = todays_date\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        new_ds3.to_netcdf(f\"HighResMIP/{general_model}/{distance[j]}/{model[i]}.NA.landfalling.storms.{distance[j]}.nc\")\n",
    "        \n",
    "        #find all points outside of the region specified by 'eastern_us.shp'. Only TCs that intersect\n",
    "        #the specified buffer region are considered. Save to NetCDF file\n",
    "    \n",
    "        print('Ocean points')\n",
    "        print(np.shape(lons3))\n",
    "        lons4, lats4, max_w4, time4 = get_ocean_points(lons3, lats3, max_w3, time3, us_shapefile) \n",
    "        \n",
    "        new_ds4 = xr.Dataset(\n",
    "            data_vars = dict(\n",
    "            clon = ([\"stormID\", \"time\"], lons4),\n",
    "            clat = ([\"stormID\", \"time\"], lats4),\n",
    "            vmax_2D = ([\"stormID\", \"time\"], max_w4),\n",
    "            time_byte = ([\"stormID\", \"time\"], time4)\n",
    "            ),\n",
    "            attrs = dict(\n",
    "            description = \"Simple NetCDF file with updated longitude, latitude, maximum wind speed, \" \n",
    "                          \"and times for all storm (tropical depressions not included) points that \" \n",
    "                         f\"are in the ocean from the model {model[i]}.\",\n",
    "            author = \"Justin Willson\",\n",
    "            creation_date = todays_date\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        new_ds4.to_netcdf(f\"HighResMIP/{general_model}/{distance[j]}/{model[i]}.NA.\"\n",
    "                          f\"landfalling.storms.{distance[j]}.ocean.pts.nc\")\n",
    "        \n",
    "        #find all points in the specified buffer region. remove points in Canada,\n",
    "        #the midwest, and the southwest. Save to NetCDF file\n",
    "        \n",
    "        print(f'{distance[j]} buffer points')\n",
    "        print(np.shape(lons4))\n",
    "        lons5, lats5, max_w5, time5 = get_landfall_points(lons4, lats4, max_w4, time4, buffer_shapefile)\n",
    "        lons5, lats5, max_w5, time5 = remove_unwanted_points(lons5, lats5, max_w5, time5)\n",
    "        \n",
    "        new_ds5 = xr.Dataset(\n",
    "        data_vars = dict(\n",
    "            clon = ([\"stormID\", \"time\"], lons5),\n",
    "            clat = ([\"stormID\", \"time\"], lats5),\n",
    "            vmax_2D = ([\"stormID\", \"time\"], max_w5),\n",
    "            time_byte = ([\"stormID\", \"time\"], time5)\n",
    "            ),\n",
    "            attrs = dict(\n",
    "            description = \"Simple NetCDF file with updated longitude, latitude, maximum wind speed, \"\n",
    "                          \"and times for all landfalling storms (tropical depressions not included) \"\n",
    "                         f\"in the eastern U.S. from the model {model[i]}. Only points where \"\n",
    "                         f\"the storm is within {distance[j]} of land are included.\",\n",
    "            author = \"Justin Willson\",\n",
    "            creation_date = todays_date\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        new_ds5.to_netcdf(f\"HighResMIP/{general_model}/{distance[j]}/{model[i]}.NA.\"\n",
    "                          f\"landfalling.storms.{distance[j]}.buffer.pts.nc\")\n",
    "                          \n",
    "        #plot the results for each distance as a check for accuracy\n",
    "        \n",
    "        gdf = gpd.read_file(\"shapefiles/eastern_us.shp\")              #open shapefile and create geodataframe\n",
    "        gdf = gdf.to_crs(\"EPSG:4326\")                                 #convert to lat and lon from platecarree\n",
    "\n",
    "        plt.figure(figsize=(12,7))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([-63, -115, 21, 55], crs=ccrs.PlateCarree())    #plot eastern U.S.\n",
    "        ax.set_title(f'{model[i]} {distance[j]}', fontsize=20)\n",
    "        \n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, alpha=0)\n",
    "        gl.xlabels_top = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        gl.xlabel_style = {'size': 14}\n",
    "        gl.ylabel_style = {'size': 14}\n",
    "        \n",
    "        gdf.plot(ax=ax, color='w', edgecolor='k')                     #plot the shapefile \n",
    "        plot_tc_points(lons5, lats5)                                  #plot the buffer points\n",
    "        plt.savefig(f'HighResMIP/{general_model}/{distance[j]}/A_{model[i]}_{distance[j]}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c491d19",
   "metadata": {},
   "source": [
    "### If the model has more than one ensemble run, combine the resulting buffer files into a larger file for each distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e29424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 19, time: 106)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -77.51953 -77.16797 -76.81641 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 33.19023 33.89267 34.24389 ... 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 12.82743 11.76152 13.25121 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'1985-09-15T18:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 23, time: 106)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -77.51953 -77.51953 -77.87109 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 32.13657 32.48779 32.48779 ... 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 12.86843 12.73715 12.34798 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'1985-09-14T18:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 25, time: 106)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -77.51953 -77.51953 -77.87109 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 32.13657 32.48779 32.48779 ... 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 12.86843 12.73715 12.34798 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'1985-09-14T18:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 102, time: 106)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -45.527344 -47.285156 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 20.19511 20.19511 21.07316 ... 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 12.72617 12.16612 11.98223 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'1985-08-12T12:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 22, time: 103)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -81.73828 -82.44141 -83.14453 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 23.70731 24.76096 25.4634 ... 0.0 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 17.08449 17.27881 17.53528 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'2021-08-27T18:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 24, time: 103)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -81.73828 -82.44141 -83.14453 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 23.70731 24.76096 25.4634 ... 0.0 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 17.08449 17.27881 17.53528 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'2021-08-27T18:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 28, time: 103)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -80.68359 -81.73828 -82.44141 ... 0.0 0.0\n",
      "    clat       (stormID, time) float32 22.30243 23.70731 24.76096 ... 0.0 0.0\n",
      "    vmax_2D    (stormID, time) float32 17.65944 17.08449 17.27881 ... 0.0 0.0\n",
      "    time_byte  (stormID, time) |S19 b'2021-08-27T12:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (stormID: 105, time: 103)\n",
      "Dimensions without coordinates: stormID, time\n",
      "Data variables:\n",
      "    clon       (stormID, time) float32 -41.308594 -45.527344 ... nan nan\n",
      "    clat       (stormID, time) float32 11.41463 11.41463 11.41463 ... nan nan\n",
      "    vmax_2D    (stormID, time) float32 12.57286 12.31678 12.21593 ... nan nan\n",
      "    time_byte  (stormID, time) |S19 b'2021-08-21T12:00:00' ... b''\n",
      "Attributes:\n",
      "    description:    NetCDF file that combines the buffer points from the 2 EC...\n",
      "    author:         Justin Willson\n",
      "    creation_date:  2022-01-12\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from tc_functions.plotting import plot_tc_points\n",
    "\n",
    "todays_date = '2022-01-12'       #YYYY-MM-DD\n",
    "general_model = 'EC-Earth3P-HR'\n",
    "distance = ['100km', '200km', '300km', 'na_basin']\n",
    "model = ['EC-Earth3P-HR(19852014)', 'EC-Earth3P-HR(20212050)']\n",
    "                                 \n",
    "individual_model = [['EC-Earth3P-HR(19852014)(1)', 'EC-Earth3P-HR(19852014)(2)'], \n",
    "                     ['EC-Earth3P-HR(20212050)(1)', 'EC-Earth3P-HR(20212050)(2)']]\n",
    "\n",
    "for i in range(len(model)):\n",
    "    for j in range(len(distance)):\n",
    "        \n",
    "        nstorms = []\n",
    "        ntimes = []\n",
    "        \n",
    "        for k in range(len(individual_model[i])):\n",
    "            \n",
    "            if distance[j] == 'na_basin':\n",
    "                track_file = f\"HighResMIP/{general_model}/{distance[j]}/{individual_model[i][k]}.NA.storms.nc\"\n",
    "            else:\n",
    "                track_file = f\"HighResMIP/{general_model}/{distance[j]}/{individual_model[i][k]}.NA.landfalling.storms.{distance[j]}.buffer.pts.nc\"\n",
    "            DS = xr.open_dataset(track_file)\n",
    "            ds_lons = DS.clon.values\n",
    "            DS.close()\n",
    "    \n",
    "            nstorms.append(np.shape(ds_lons)[0])\n",
    "            ntimes.append(np.shape(ds_lons)[1])\n",
    "    \n",
    "        comb_lons = np.full((sum(nstorms), max(ntimes)), 0, dtype = np.float32)   # initialize combined arrays \n",
    "        comb_lats = np.full((sum(nstorms), max(ntimes)), 0, dtype = np.float32)\n",
    "        comb_maxw = np.full((sum(nstorms), max(ntimes)), 0, dtype = np.float32)\n",
    "        comb_time = np.full((sum(nstorms), max(ntimes)), b'', dtype = '|S19')\n",
    "        \n",
    "        num = 0\n",
    "        for k in range(len(individual_model[i])):\n",
    "            \n",
    "            if distance[j] == 'na_basin':\n",
    "                track_file = f\"HighResMIP/{general_model}/{distance[j]}/{individual_model[i][k]}.NA.storms.nc\"\n",
    "            else:\n",
    "                track_file = f\"HighResMIP/{general_model}/{distance[j]}/{individual_model[i][k]}.NA.landfalling.storms.{distance[j]}.buffer.pts.nc\"\n",
    "            DS = xr.open_dataset(track_file)\n",
    "            ds_lons = DS.clon.values\n",
    "            ds_lats = DS.clat.values\n",
    "            ds_maxw = DS.vmax_2D.values\n",
    "            ds_time = DS.time_byte.values\n",
    "            DS.close()\n",
    "            \n",
    "            for n in range(nstorms[k]):\n",
    "                for m in range(ntimes[k]):\n",
    "                    comb_lons[num,m] = ds_lons[n,m]\n",
    "                    comb_lats[num,m] = ds_lats[n,m]\n",
    "                    comb_maxw[num,m] = ds_maxw[n,m] \n",
    "                    comb_time[num,m] = ds_time[n,m]\n",
    "                num += 1\n",
    "                \n",
    "        new_ds = xr.Dataset(                                  # create and save a new combined netcdf file\n",
    "            data_vars = dict(\n",
    "            clon = ([\"stormID\", \"time\"], comb_lons),\n",
    "            clat = ([\"stormID\", \"time\"], comb_lats),\n",
    "            vmax_2D = ([\"stormID\", \"time\"], comb_maxw),\n",
    "            time_byte = ([\"stormID\", \"time\"], comb_time)\n",
    "            ),\n",
    "            attrs = dict(\n",
    "            description = f\"NetCDF file that combines the buffer points from the {len(individual_model[i])} \"\n",
    "                          f\"{model[i]} ensembles.\",\n",
    "            author = \"Justin Willson\",\n",
    "            creation_date = todays_date\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        print(new_ds)\n",
    "        \n",
    "        if distance[j] == 'na_basin':\n",
    "            new_ds.to_netcdf(f'HighResMIP/{general_model}/{distance[j]}/{model[i]}.NA.storms.nc')\n",
    "        else:\n",
    "            new_ds.to_netcdf(f'HighResMIP/{general_model}/{distance[j]}/{model[i]}.NA.landfalling.storms.{distance[j]}.buffer.pts.nc')\n",
    "            \n",
    "        #plot the results for each distance as a check for accuracy\n",
    "        \n",
    "        gdf = gpd.read_file(\"shapefiles/eastern_us.shp\")              #open shapefile and create geodataframe\n",
    "        gdf = gdf.to_crs(\"EPSG:4326\")                                 #convert to lat and lon from platecarree\n",
    "\n",
    "        plt.figure(figsize=(12,7))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([-63, -115, 21, 55], crs=ccrs.PlateCarree())    #plot eastern U.S.\n",
    "        ax.set_title(f'{model[i]} {distance[j]}', fontsize=20)\n",
    "        \n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, alpha=0)\n",
    "        gl.xlabels_top = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        gl.xlabel_style = {'size': 14}\n",
    "        gl.ylabel_style = {'size': 14}\n",
    "        \n",
    "        gdf.plot(ax=ax, color='w', edgecolor='k')                     #plot the shapefile \n",
    "        plot_tc_points(comb_lons, comb_lats)                          #plot the buffer points\n",
    "        plt.savefig(f'HighResMIP/{general_model}/{distance[j]}/A_{model[i]}_{distance[j]}.png')\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
