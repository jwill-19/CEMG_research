{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03acaff",
   "metadata": {},
   "source": [
    "# Plotting Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca4860",
   "metadata": {},
   "source": [
    "### Program to make a cdf plot of IBTrACS, REF combined, RCP4.5 combined, and RCP8.5 combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1293df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#track_file1 = \"200km_analysis/IBTrACS.NA.v04r00.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file1 = \"300km_analysis/REF.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file2 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "#track_file2 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "\n",
    "DS1 = xr.open_dataset(track_file1)\n",
    "max_w1 = DS1.vmax_2D.values\n",
    "DS1.close()\n",
    "\n",
    "DS2 = xr.open_dataset(track_file2)\n",
    "max_w2 = DS2.vmax_2D.values\n",
    "DS2.close()\n",
    "\"\"\"\n",
    "DS3 = xr.open_dataset(track_file3)\n",
    "max_w3 = DS3.vmax_2D.values\n",
    "DS3.close()\n",
    "\n",
    "DS4 = xr.open_dataset(track_file4)\n",
    "max_w4 = DS4.vmax_2D.values\n",
    "DS4.close()\n",
    "\"\"\"\n",
    "nstorms1 = np.shape(max_w1)[0]\n",
    "ntimes1 = np.shape(max_w1)[1]\n",
    "\n",
    "nstorms2 = np.shape(max_w2)[0]\n",
    "ntimes2 = np.shape(max_w2)[1]\n",
    "\"\"\"\n",
    "nstorms3 = np.shape(max_w3)[0]\n",
    "ntimes3 = np.shape(max_w3)[1]\n",
    "\n",
    "nstorms4 = np.shape(max_w4)[0]\n",
    "ntimes4 = np.shape(max_w4)[1]\n",
    "\"\"\"\n",
    "total_list1 = []\n",
    "for i in range(nstorms1):\n",
    "    for j in range(ntimes1):\n",
    "        total_list1.append(max_w1[i,j])\n",
    "\n",
    "total_array1 = np.asarray(total_list1)  #calculate the wind speed for each storm's points in buffer region\n",
    "total_array1 = total_array1[total_array1 > 0] #remove 0 entries\n",
    "#total_array1 = total_array1 * 0.51444444444444    #convert to m/s from knots (if IBTrACS)\n",
    "\n",
    "total_list2 = []\n",
    "for i in range(nstorms2):\n",
    "    for j in range(ntimes2):\n",
    "        total_list2.append(max_w2[i,j])\n",
    "\n",
    "total_array2 = np.asarray(total_list2)  #calculate the wind speed for each storm's points in buffer region\n",
    "total_array2 = total_array2[total_array2 > 0] #remove 0 entries\n",
    "\n",
    "\"\"\"\n",
    "total_list3 = []\n",
    "for i in range(nstorms3):\n",
    "    for j in range(ntimes3):\n",
    "        total_list3.append(max_w3[i,j])\n",
    "\n",
    "total_array3 = np.asarray(total_list3)  #calculate the wind speed for each storm's points in buffer region\n",
    "total_array3 = total_array3[total_array3 > 0] #remove 0 entries\n",
    "\n",
    "\n",
    "total_list4 = []\n",
    "for i in range(nstorms4):\n",
    "    for j in range(ntimes4):\n",
    "        total_list4.append(max_w4[i,j])\n",
    "\n",
    "total_array4 = np.asarray(total_list4)  #calculate the wind speed for each storm's points in buffer region\n",
    "total_array4 = total_array4[total_array4 > 0] #remove 0 entries\n",
    "\"\"\"\n",
    "bin_intervals = np.arange(0, 100, 5)\n",
    "fig, ax = plt.subplots(figsize=(12, 7), tight_layout=True)\n",
    "ax.hist(total_array1, bins=bin_intervals, cumulative=True, density=True, histtype = 'step', color='b', linewidth=2, label='REF')\n",
    "ax.hist(total_array2, bins=bin_intervals, cumulative=True, density=True, histtype = 'step', color='r', linewidth=2, label='RCP8.5')\n",
    "#ax.hist(total_array3, bins=bin_intervals, density=True, histtype = 'step', color='r', linewidth=2, label='RCP4.5')\n",
    "#ax.hist(total_array4, bins=bin_intervals, density=True, histtype = 'step', color='k', linewidth=2, label='RCP8.5')\n",
    "ax.set_xlabel('Wind Speed (m/s)', fontsize=16)\n",
    "ax.set_ylabel('Probability', fontsize=16)\n",
    "ax.set_title('PDF Intensity Distributions (within 200km buffer)', fontsize=22)\n",
    "ax.legend(loc='upper left')\n",
    "plt.savefig(\"figures_in_report/pdf_intdistributions_300km(85cdf).png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab144eb",
   "metadata": {},
   "source": [
    "### Program to make pdf plots for all 3 combined into one figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461577a",
   "metadata": {},
   "source": [
    "All intensities, avg intensity, and max intensity distributions are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f402a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "track_file1 = \"100km_analysis/IBTrACS.NA.v04r00.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file2 = \"100km_analysis/REF.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file3 = \"100km_analysis/RCP45.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file4 = \"100km_analysis/RCP85.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "\n",
    "track_file5 = \"200km_analysis/IBTrACS.NA.v04r00.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file6 = \"200km_analysis/REF.COMB.NA.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file7 = \"200km_analysis/RCP45.COMB.NA.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file8 = \"200km_analysis/RCP85.COMB.NA.landfalling.storms.200km.buffer.pts.nc\"\n",
    "\n",
    "track_file9 = \"300km_analysis/IBTrACS.NA.v04r00.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file10 = \"300km_analysis/REF.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file11 = \"300km_analysis/RCP45.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file12 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "\n",
    "file_list = [[track_file1, track_file2, track_file3, track_file4],     #create list of track files\n",
    "             [track_file5, track_file6, track_file7, track_file8],\n",
    "             [track_file9, track_file10, track_file11, track_file12]]\n",
    "\n",
    "file_array = np.asarray(file_list)             #convert list to array for better indexing\n",
    "\n",
    "maxw_list = [[], [], []]                       #create empty lists to store data from track files\n",
    "\n",
    "file_groups = np.shape(file_array)[0]          #calculate number of file groups(buffers) and files per group\n",
    "files = np.shape(file_array)[1]\n",
    "\n",
    "for i in range(file_groups):                   #iterate through every track file buffer group\n",
    "    for j in range(files):                     #iterate through every track file in group\n",
    "        DS = xr.open_dataset(file_array[i,j])  #open file and extract arrays\n",
    "        max_w = DS.vmax_2D.values\n",
    "        DS.close()\n",
    "        maxw_list[i].append(max_w)             #append arrays into list\n",
    "\n",
    "maxw_array = np.asarray(maxw_list)             #convert list to array for better indexing\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(nrows=3, ncols=3, \n",
    "                                                              figsize=(10,10)) #initialize figure and axes\n",
    "\n",
    "axes1 = [ax1, ax4, ax7]              #create list of axes\n",
    "axes2 = [ax2, ax5, ax8]\n",
    "axes3 = [ax3, ax6, ax9]\n",
    "\n",
    "bin_intervals = np.arange(0, 100, 5) #set bin intervals\n",
    "                                                         \n",
    "i = 0                                #create index for iteration\n",
    "for ax in axes1:                     #loop through each ax instance\n",
    "    total_list = []\n",
    "    for j in range(files):\n",
    "        total_list.append(maxw_array[i,j])\n",
    "    total_array = np.asarray(total_list)  \n",
    "    \n",
    "    for j in range(files):\n",
    "        total_array[j] = total_array[j][total_array[j] > 0]\n",
    "        \n",
    "    ibtracs_median = np.median(total_array[0])* 0.51444444444444\n",
    "    ref_median = np.median(total_array[1])\n",
    "    rcp45_median = np.median(total_array[2])\n",
    "    rcp85_median = np.median(total_array[3])\n",
    "    \n",
    "    y_value = 0.001\n",
    "    \n",
    "    ax.hist(total_array[0]* 0.51444444444444, bins=bin_intervals, density=True, histtype = 'step', color='k', linewidth=2)\n",
    "    ax.hist(total_array[1], bins=bin_intervals, density=True, histtype = 'step', color='b', linewidth=2)\n",
    "    ax.hist(total_array[2], bins=bin_intervals, density=True, histtype = 'step', color='orange', linewidth=2)\n",
    "    ax.hist(total_array[3], bins=bin_intervals, density=True, histtype = 'step', color='r', linewidth=2)\n",
    "    ax.plot(ibtracs_median, y_value, 'x', color='k')\n",
    "    ax.plot(ref_median, y_value, 'x', color='b')\n",
    "    ax.plot(rcp45_median, y_value, 'x', color='orange')\n",
    "    ax.plot(rcp85_median, y_value, 'x', color='r')\n",
    "    \n",
    "    i = i+1\n",
    "    \n",
    "i = 0\n",
    "for ax in axes2:\n",
    "    max_list = []\n",
    "    for j in range(files):\n",
    "        nstorms = np.shape(maxw_array[i,j])[0]\n",
    "        max_int_list = []\n",
    "        for k in range(nstorms):\n",
    "            max_int = max(maxw_array[i,j][k,:])\n",
    "            max_int_list.append(max_int)\n",
    "        max_list.append(np.asarray(max_int_list))    \n",
    "        \n",
    "    max_array = np.asarray(max_list)\n",
    "    \n",
    "    for j in range(files):\n",
    "        max_array[j] = max_array[j][max_array[j] > 0]\n",
    "        \n",
    "    ibtracs_median = np.median(max_array[0])* 0.51444444444444\n",
    "    ref_median = np.median(max_array[1])\n",
    "    rcp45_median = np.median(max_array[2])\n",
    "    rcp85_median = np.median(max_array[3])\n",
    "    \n",
    "    y_value = 0.001\n",
    "    \n",
    "    ax.hist(max_array[0]* 0.51444444444444, bins=bin_intervals, density=True, histtype = 'step', color='k', linewidth=2)\n",
    "    ax.hist(max_array[1], bins=bin_intervals, density=True, histtype = 'step', color='b', linewidth=2)\n",
    "    ax.hist(max_array[2], bins=bin_intervals, density=True, histtype = 'step', color='orange', linewidth=2)\n",
    "    ax.hist(max_array[3], bins=bin_intervals, density=True, histtype = 'step', color='r', linewidth=2)\n",
    "    ax.plot(ibtracs_median, y_value, 'x', color='k')\n",
    "    ax.plot(ref_median, y_value, 'x', color='b')\n",
    "    ax.plot(rcp45_median, y_value, 'x', color='orange')\n",
    "    ax.plot(rcp85_median, y_value, 'x', color='r')\n",
    "    \n",
    "    i = i+1\n",
    "    \n",
    "i = 0\n",
    "for ax in axes3:\n",
    "    avg_list = []\n",
    "    for j in range(files):\n",
    "        nstorms = np.shape(maxw_array[i,j])[0]\n",
    "        avg_int_list = []\n",
    "        for k in range(nstorms):\n",
    "            storm = maxw_array[i,j][k,:]\n",
    "            storm = storm[storm > 0]\n",
    "            if len(storm) == 0:\n",
    "                avg_int = 0\n",
    "            else:\n",
    "                avg_int = np.mean(storm)\n",
    "            avg_int_list.append(avg_int)\n",
    "        avg_list.append(np.asarray(avg_int_list))\n",
    "            \n",
    "    avg_array = np.asarray(avg_list)\n",
    "    \n",
    "    for j in range(files):\n",
    "        avg_array[j] = avg_array[j][avg_array[j] > 0]\n",
    "        \n",
    "    ibtracs_median = np.median(avg_array[0])* 0.51444444444444\n",
    "    ref_median = np.median(avg_array[1])\n",
    "    rcp45_median = np.median(avg_array[2])\n",
    "    rcp85_median = np.median(avg_array[3])\n",
    "    \n",
    "    y_value = 0.001\n",
    "    \n",
    "    ax.hist(avg_array[0]* 0.51444444444444, bins=bin_intervals, density=True, histtype = 'step', color='k', linewidth=2)\n",
    "    ax.hist(avg_array[1], bins=bin_intervals, density=True, histtype = 'step', color='b', linewidth=2)\n",
    "    ax.hist(avg_array[2], bins=bin_intervals, density=True, histtype = 'step', color='orange', linewidth=2)\n",
    "    ax.hist(avg_array[3], bins=bin_intervals, density=True, histtype = 'step', color='r', linewidth=2)\n",
    "    ax.plot(ibtracs_median, y_value, 'x', color='k')\n",
    "    ax.plot(ref_median, y_value, 'x', color='b')\n",
    "    ax.plot(rcp45_median, y_value, 'x', color='orange')\n",
    "    ax.plot(rcp85_median, y_value, 'x', color='r')\n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "fontsize = 12\n",
    "ax8.set_xlabel('Wind Speed (m/s)', fontsize=fontsize)               #set axis labels only once\n",
    "ax4.set_ylabel('Probability', fontsize=fontsize)\n",
    "ax1.set_title('All Intensities: 100km buffer', fontsize=fontsize)  #set specific titles for each axis\n",
    "ax4.set_title('200km buffer', fontsize=fontsize)\n",
    "ax7.set_title('300km buffer', fontsize=fontsize)\n",
    "ax2.set_title('Max Intensities: 100km buffer', fontsize=fontsize)\n",
    "ax5.set_title('200km buffer', fontsize=fontsize)\n",
    "ax8.set_title('300km buffer', fontsize=fontsize)\n",
    "ax3.set_title('Avg Intensities: 100km buffer', fontsize=fontsize)\n",
    "ax6.set_title('200km buffer', fontsize=fontsize)\n",
    "ax9.set_title('300km buffer', fontsize=fontsize)\n",
    "\n",
    "ibtracs_patch = mpatches.Patch(fill=False, color='k', linewidth=2, label='IBTrACS')    #create a legend\n",
    "ref_patch = mpatches.Patch(fill=False, color='b', linewidth=2, label='REF') \n",
    "rcp45_patch = mpatches.Patch(fill=False, color='orange', linewidth=2, label='RCP4.5') \n",
    "rcp85_patch = mpatches.Patch(fill=False, color='r', linewidth=2, label='RCP8.5')\n",
    "ibtracs_med_patch, = plt.plot([], [], 'x', color='k', linewidth=2, label='IBTrACS median')    \n",
    "ref_med_patch, = plt.plot([], [], 'x', color='b', linewidth=2, label='REF median') \n",
    "rcp45_med_patch, = plt.plot([], [], 'x', color='orange', linewidth=2, label='RCP4.5 median') \n",
    "rcp85_med_patch, = plt.plot([], [], 'x', color='r', linewidth=2, label='RCP8.5 median') \n",
    "ax8.legend(handles=[ibtracs_patch, ref_patch, rcp45_patch, rcp85_patch, ibtracs_med_patch, ref_med_patch, \n",
    "                    rcp45_med_patch, rcp85_med_patch], loc='upper center', \n",
    "           bbox_to_anchor=(0.5, -0.2),fancybox=False, shadow=False, ncol=3)\n",
    "\n",
    "plt.savefig(\"figures_in_report/pdf_intdistributions(newsize).png\")           #save and close figure\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57fd9e",
   "metadata": {},
   "source": [
    "### Program to make a plot of the translation speed distributions of all combined files in each buffer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26bddf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tc_analysis.tc_functions import *\n",
    "\n",
    "track_file1 = \"100km_analysis/IBTrACS.NA.v04r00.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file2 = \"100km_analysis/REF.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file3 = \"100km_analysis/RCP45.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "track_file4 = \"100km_analysis/RCP85.COMB.NA.landfalling.storms.100km.buffer.pts.nc\"\n",
    "\n",
    "track_file5 = \"200km_analysis/IBTrACS.NA.v04r00.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file6 = \"200km_analysis/REF.COMB.NA.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file7 = \"200km_analysis/RCP45.COMB.NA.landfalling.storms.200km.buffer.pts.nc\"\n",
    "track_file8 = \"200km_analysis/RCP85.COMB.NA.landfalling.storms.200km.buffer.pts.nc\"\n",
    "\n",
    "track_file9 = \"300km_analysis/IBTrACS.NA.v04r00.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file10 = \"300km_analysis/REF.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file11 = \"300km_analysis/RCP45.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file12 = \"300km_analysis/RCP85.COMB.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "\n",
    "file_list = [[track_file1, track_file2, track_file3, track_file4],     #create list of track files\n",
    "             [track_file5, track_file6, track_file7, track_file8],\n",
    "             [track_file9, track_file10, track_file11, track_file12]]\n",
    "\n",
    "file_array = np.asarray(file_list)               #convert list to array for better indexing\n",
    "\n",
    "ts_list = [[], [], []]                           #create empty lists to store data from track files\n",
    "\n",
    "file_groups = np.shape(file_array)[0]            #calculate number of file groups(buffers) and files per group\n",
    "files = np.shape(file_array)[1]\n",
    "\n",
    "for i in range(file_groups):                     #iterate through every track file buffer group\n",
    "    for j in range(files):                       #iterate through every track file in group\n",
    "        ts_dist = []                             #initialize ts distribution list\n",
    "        \n",
    "        DS = xr.open_dataset(file_array[i,j])    #open file and extract arrays\n",
    "        lons = DS.clon.values\n",
    "        lats = DS.clat.values\n",
    "        time = DS.time_str.values\n",
    "        DS.close()\n",
    "        \n",
    "        nstorms = np.shape(lons)[0]              #get number of storms and times\n",
    "        ntimes = np.shape(lons)[1]\n",
    "        \n",
    "        for k in range(nstorms):\n",
    "            lon_array = lons[k,:]                #get lons and lats for each storm\n",
    "            lat_array = lats[k,:]\n",
    "            lon_array = lon_array[lon_array < 0] #only keep legitimate TC track points\n",
    "            lat_array = lat_array[lat_array > 0]\n",
    "    \n",
    "            if len(lon_array) != len(lat_array): #raise error if not all points have both a lon and lat coord\n",
    "                raise ValueError('lat/lon lengths are not equal at storm ' + str(i))\n",
    "            \n",
    "            for m in range(len(lon_array)):\n",
    "                \n",
    "                if m == len(lon_array)-1:        #avoid conflicts at last point \n",
    "                    continue\n",
    "                \n",
    "                if file_array[i,j].count('IBTrACS') == 1:\n",
    "                    time1 = np.datetime64(time[k,m].decode('UTF-8'))       \n",
    "                    time2 = np.datetime64(time[k,m+1].decode('UTF-8'))\n",
    "                    \n",
    "                if file_array[i,j].count('IBTrACS') == 0:\n",
    "                    time1_str = str(time[k,m])                #get initial strings in integer format\n",
    "                    time2_str = str(time[k,m+1])              #convert to np.datetime64 format\n",
    "                    time1_dt = time1_str[0:4] + '-' + time1_str[4:6] + '-' + time1_str[6:8] + ' ' + time1_str[8:10] + ':00:00'\n",
    "                    time2_dt = time2_str[0:4] + '-' + time2_str[4:6] + '-' + time2_str[6:8] + ' ' + time2_str[8:10] + ':00:00'\n",
    "                    time1 = np.datetime64(time1_dt)\n",
    "                    time2 = np.datetime64(time2_dt)\n",
    "                    \n",
    "                time_diff = np.timedelta64(time2-time1, 'h')  #get difference in times\n",
    "                expected_diff = np.timedelta64(6, 'h')        #set expected difference to 6 hours\n",
    "                hours = 6.0                                   #numerical value of expected time diff between pts\n",
    "                \n",
    "                if time_diff == expected_diff:                #all time differences should equal expected difference\n",
    "                    track_pt1 = (lon_array[m], lat_array[m])  #calculate translation speed in km/h for each point\n",
    "                    track_pt2 = (lon_array[m+1], lat_array[m+1])\n",
    "                    ts = get_distance(track_pt1, track_pt2) / hours \n",
    "                    ts_dist.append(ts)\n",
    "        \n",
    "        ts_list[i].append(ts_dist)               #append arrays into list\n",
    "        \n",
    "ts_array = np.asarray(ts_list)                   #convert to np.ndarray\n",
    "\n",
    "fig, ((ax1), (ax2), (ax3)) = plt.subplots(nrows=3, ncols=1, figsize=(12,12)) #initialize figure and axes\n",
    "\n",
    "axes = [ax1, ax2, ax3]                           #create list of axes\n",
    "\n",
    "bin_intervals = np.arange(0, 100, 5)             #set bin intervals\n",
    "\n",
    "i = 0                                            #create index for iteration\n",
    "for ax in axes:                                  #loop through each ax instance\n",
    "    ibtracs = ts_array[i,0]                      #get ts distributions and their medians\n",
    "    ref = ts_array[i,1]\n",
    "    rcp45 = ts_array[i,2]\n",
    "    rcp85 = ts_array[i,3]\n",
    "    \n",
    "    ibtracs_median = np.median(ts_array[i,0])\n",
    "    ref_median = np.median(ts_array[i,1])\n",
    "    rcp45_median = np.median(ts_array[i,2])\n",
    "    rcp85_median = np.median(ts_array[i,3])\n",
    "    \n",
    "    y_value = 0.001                              #plot the distributions and their medians\n",
    "    \n",
    "    ax.hist(ibtracs, bins=bin_intervals, density=True, histtype = 'step', color='k', linewidth=2)\n",
    "    ax.hist(ref, bins=bin_intervals, density=True, histtype = 'step', color='b', linewidth=2)\n",
    "    ax.hist(rcp45, bins=bin_intervals, density=True, histtype = 'step', color='orange', linewidth=2)\n",
    "    ax.hist(rcp85, bins=bin_intervals, density=True, histtype = 'step', color='r', linewidth=2)\n",
    "    ax.plot(ibtracs_median, y_value, 'x', color='k')\n",
    "    ax.plot(ref_median, y_value, 'x', color='b')\n",
    "    ax.plot(rcp45_median, y_value, 'x', color='orange')\n",
    "    ax.plot(rcp85_median, y_value, 'x', color='r')\n",
    "    \n",
    "    i = i+1\n",
    "    \n",
    "fontsize = 16\n",
    "ax3.set_xlabel('Translation Speed (km/h)', fontsize=fontsize)               #set axis labels only once\n",
    "ax2.set_ylabel('Probability', fontsize=fontsize)\n",
    "ax1.set_title('All Translation Speeds: 100km buffer', fontsize=fontsize)   #set specific titles for each axis\n",
    "ax2.set_title('200km buffer', fontsize=fontsize)\n",
    "ax3.set_title('300km buffer', fontsize=fontsize)\n",
    "\n",
    "ibtracs_patch = mpatches.Patch(fill=False, color='k', linewidth=2, label='IBTrACS')    #create a legend\n",
    "ref_patch = mpatches.Patch(fill=False, color='b', linewidth=2, label='REF') \n",
    "rcp45_patch = mpatches.Patch(fill=False, color='orange', linewidth=2, label='RCP4.5') \n",
    "rcp85_patch = mpatches.Patch(fill=False, color='r', linewidth=2, label='RCP8.5')\n",
    "ibtracs_med_patch, = plt.plot([], [], 'x', color='k', linewidth=2, label='IBTrACS median')    \n",
    "ref_med_patch, = plt.plot([], [], 'x', color='b', linewidth=2, label='REF median') \n",
    "rcp45_med_patch, = plt.plot([], [], 'x', color='orange', linewidth=2, label='RCP4.5 median') \n",
    "rcp85_med_patch, = plt.plot([], [], 'x', color='r', linewidth=2, label='RCP8.5 median') \n",
    "ax3.legend(handles=[ibtracs_patch, ref_patch, rcp45_patch, rcp85_patch, ibtracs_med_patch, ref_med_patch, \n",
    "                    rcp45_med_patch, rcp85_med_patch], loc='upper center', \n",
    "                    bbox_to_anchor=(0.5, -0.2),fancybox=False, shadow=False, ncol=3)\n",
    "\n",
    "plt.savefig(\"figures_in_report/pdf_ts_dists.png\")           #save and close figure\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfbfd6",
   "metadata": {},
   "source": [
    "### Program to plot the buffer points or buffer TC tracks in every file color coded by intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc1f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from tc_analysis.tc_functions import *\n",
    "\n",
    "track_file1 = \"300km_analysis/IBTrACS.NA.v04r00.landfalling.storms.300km.buffer.pts.nc\" #all track files that will be plotted (points)\n",
    "track_file2 = \"300km_analysis/REF.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file3 = \"300km_analysis/REF002.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file4 = \"300km_analysis/REF003.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file5 = \"300km_analysis/RCP45.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file6 = \"300km_analysis/RCP45002.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file7 = \"300km_analysis/RCP45003.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file8 = \"300km_analysis/RCP85.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file9 = \"300km_analysis/RCP85002.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "track_file10 = \"300km_analysis/RCP85003.NA.landfalling.storms.300km.buffer.pts.nc\"\n",
    "\"\"\"\n",
    "track_file1 = \"300km_analysis/IBTrACS.NA.v04r00.landfalling.storms.300km.nc\"  #all track files that will be plotted (tracks)\n",
    "track_file2 = \"300km_analysis/REF.NA.landfalling.storms.300km.nc\"\n",
    "track_file3 = \"300km_analysis/REF002.NA.landfalling.storms.300km.nc\"\n",
    "track_file4 = \"300km_analysis/REF003.NA.landfalling.storms.300km.nc\"\n",
    "track_file5 = \"300km_analysis/RCP45.NA.landfalling.storms.300km.nc\"\n",
    "track_file6 = \"300km_analysis/RCP45002.NA.landfalling.storms.300km.nc\"\n",
    "track_file7 = \"300km_analysis/RCP45003.NA.landfalling.storms.300km.nc\"\n",
    "track_file8 = \"300km_analysis/RCP85.NA.landfalling.storms.300km.nc\"\n",
    "track_file9 = \"300km_analysis/RCP85002.NA.landfalling.storms.300km.nc\"\n",
    "track_file10 = \"300km_analysis/RCP85003.NA.landfalling.storms.300km.nc\"\n",
    "\"\"\"\n",
    "\n",
    "file_list = [track_file1, track_file2, track_file3, track_file4, track_file5, track_file6, track_file7,\n",
    "            track_file8, track_file9, track_file10]\n",
    "                #store track file names in a list\n",
    "\n",
    "lons_list = []  #create empty lists to store data from track files\n",
    "lats_list = []\n",
    "maxw_list = []\n",
    "time_list = []\n",
    "\n",
    "for i in range(len(file_list)):         #iterate through every track file\n",
    "    DS = xr.open_dataset(file_list[i])  #open file and extract arrays\n",
    "    lons = DS.clon.values\n",
    "    lats = DS.clat.values\n",
    "    max_w = DS.vmax_2D.values\n",
    "    time = DS.time_str.values\n",
    "    DS.close()\n",
    "    lons_list.append(lons)              #append arrays into list\n",
    "    lats_list.append(lats)\n",
    "    maxw_list.append(max_w)\n",
    "    time_list.append(time)\n",
    " \n",
    "\n",
    "gdf = gpd.read_file(\"shapefiles/continental_us.shp\")     #open shapefile and create geodataframe\n",
    "gdf = gdf.to_crs(\"EPSG:4326\")                            #convert to lat and lon from platecarree\n",
    "\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12)) = plt.subplots(nrows=4, ncols=3, \n",
    "                        sharex=True, sharey=True, figsize=(16,16), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "                                                         #initialize figure and axes\n",
    "\n",
    "ax1.set_visible(False)                                   #remove unwanted axes\n",
    "ax3.set_visible(False)\n",
    "\n",
    "axes = [ax2, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]    #create list of axes\n",
    "\n",
    "i = 0                                                           #create index for iteration\n",
    "for ax in axes:                                                 #loop through each ax instance\n",
    "    ax.set_extent([-63, -99, 20, 46], crs=ccrs.PlateCarree())   #plot eastern U.S. 100,200: -65, -99, 22, 46\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, alpha=0)\n",
    "    gl.xlabels_top = False                                      #format the labels\n",
    "    gl.ylabels_right = False\n",
    "    gl.ylabels_left = True\n",
    "    gl.xlabels_bottom = True\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlocator = mticker.FixedLocator([-96, -86, -76, -66])\n",
    "    gl.ylocator = mticker.FixedLocator([24, 31, 38, 45])\n",
    "    gl.xlabel_style = {'size': 11}\n",
    "    gl.ylabel_style = {'size': 11}\n",
    "    \n",
    "    gdf.plot(ax=ax, color='palegreen', edgecolor='k')           #plot shapefile in every figure\n",
    "    \n",
    "    if i == 0:                                                    #plot values from each file (IBTrACS loc=0, knots)\n",
    "        ibtracs_plot_points_byintensity(lons_list[i], lats_list[i], maxw_list[i], ax)\n",
    "        #ibtracs_plot_trajectories_byintensity(lons_list[i], lats_list[i], maxw_list[i], ax)\n",
    "    else:\n",
    "        ref_plot_points_byintensity(lons_list[i], lats_list[i], maxw_list[i], ax) #ref loc=1-10, m/s      \n",
    "        #ref_plot_trajectories_byintensity(lons_list[i], lats_list[i], maxw_list[i], ax)\n",
    "    \n",
    "    i = i+1                                                     #update the counter\n",
    "    \n",
    "fontsize = 16\n",
    "ax2.set_title('IBTrACS', fontsize=fontsize)            #set titles for plots\n",
    "ax4.set_title('REF', fontsize=fontsize)\n",
    "ax5.set_title('REF: 002', fontsize=fontsize)\n",
    "ax6.set_title('REF: 003', fontsize=fontsize)\n",
    "ax7.set_title('RCP4.5', fontsize=fontsize)\n",
    "ax8.set_title('RCP4.5: 002', fontsize=fontsize)\n",
    "ax9.set_title('RCP4.5: 003', fontsize=fontsize)\n",
    "ax10.set_title('RCP8.5', fontsize=fontsize)\n",
    "ax11.set_title('RCP8.5: 002', fontsize=fontsize)\n",
    "ax12.set_title('RCP8.5: 003', fontsize=fontsize)\n",
    "\n",
    "yellow_patch = mpatches.Patch(color='y', label='TD')    #create a legend\n",
    "green_patch = mpatches.Patch(color='g', label='TS') \n",
    "cyan_patch = mpatches.Patch(color='c', label='Cat1') \n",
    "blue_patch = mpatches.Patch(color='b', label='Cat2') \n",
    "red_patch = mpatches.Patch(color='r', label='Cat3') \n",
    "black_patch = mpatches.Patch(color='k', label='Cat4/5') \n",
    "ax11.legend(handles=[yellow_patch, green_patch, cyan_patch, blue_patch, \n",
    "                    red_patch, black_patch], loc='upper center', \n",
    "                    bbox_to_anchor=(0.5, -0.2),fancybox=False, shadow=False, ncol=3)\n",
    "\n",
    "plt.savefig(\"figures_in_report/all_buffer_pts_300km.png\")   #save figure in same directory\n",
    "plt.close(fig)                                          #close figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
